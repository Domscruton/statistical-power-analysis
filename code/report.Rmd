---
title: "Statistical Power Analysis"
author: "Dominic Scruton"
date: "February 2022"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.width = 9, fig.height = 4)
```

```{r 1-initialize-session, echo = FALSE, message = FALSE, results = FALSE, warning = FALSE}
packages <- c("data.table", "dslabs", "dplyr", "ggplot2", 
              "knitr", "rmarkdown", "ggpubr")
fun_check_packages <- function(x){
  # require returns warning (library returns error) and implicit True/False 
  # statement depending on whether package is available or not
  # character.only enables use of character vector as object
  if(!require(x, character.only = TRUE)){
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
}
lapply(packages, fun_check_packages)

pathProj <- paste0("C:/Users/User/Documents/Projects/Data Science Projects/", 
                   "statistical-power-analysis/")
pathCode <- paste0(pathProj, "code/")

# Source functions
source(paste0(pathCode, "sample-size-function.R"))

# Set seed for reproducibility
cRandSeed <- 567
set.seed(cRandSeed)
```


# 1 Introduction

The Student's t-test is a parametric test for assessing whether there is a statistically significant difference in the mean of two samples (and more generally for determining whether the mean of a sample differs in value to a constant or another sample mean)^[Student's t-test is used for inference when fitting parametric models such as the Gaussian Linear Model]. The test, however, places strong assumptions on the data, in particular that the mean of each sample is normally distributed. The Randomization test has been long-proposed as an alternative to the t-test and has risen to prominence in the age of computational Statistical Inference. 

We consider how the size and power of the two-sample t-test and randomization test for the means of two samples vary under different scenarios. These include changes in sample size, variance and difference in mean between the samples. Further, deviations from normality are examined through the use of simulations from a Gamma distribution with varying shape and rate parameters. It is seen that the non-parametric randomization test is more robust to deviations from normality but that the t-test is asymptotically robust, measured via power and size. 

As a motivating example, a comparison of murder rates between Southern and Northern US states is utilized; we would like to assess our prior expectations that Southern states have higher homicide rates.


# 2 Methodology

## 2.1 Two-Sample t-test

Because the data are not paired, we consider a two-sample t-test to assess whether the mean homicide rate of the two regions, South and North East, are different. The two-sample t-test has three key assumptions:

* Observations sampled independently from the two populations being compared
	
* Sample mean, $\bar{X}$ follows a normal distribution
	
* Data from the two samples have equal variances^[The equal variance assumption can be dropped and is known as Welch's t-test]
	
For large samples, the two-sample t-test is reasonably robust to deviance from normality, as attested by the __Central Limit Theorem (CLT)__. 

The two-sample t-test statistic is given by:

$$t = \frac{\bar{X}_1 - \bar{X}_2}{S_p \sqrt{\frac{2}{n}}}$$

where $S_p = \sqrt{\frac{S_{X_1}^2 + S_{X_2}^2}{2}}$ is the _Pooled Standard Deviation_, $n = n_1 + n_2$ and $S_{X_j}$ is the standard error for sample $j$. Most two-sample t-tests are robust to all but the strongest deviations from these assumptions. 

One can extend this statistic to cases where sample sizes differ:

$$t = \frac{\bar{X}_1 - \bar{X}_2}{S_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$

where the Pooled Standard deviation becomes:

$$S_p = \sqrt{\frac{(n_1 - 1)S_{X_1}^2 + (n_2 - 1)S_{X_2}^2}{n_1 + n_2 - 2}}$$

Relaxing the assumption of identical population variances for the two groups, we have Welch's t-test:

$$t = \frac{\bar{X}_1 - \bar{X}_2}{S_P}$$

where

$$S_p = \sqrt{\frac{s_{X_1}^2}{n_1} + \frac{s_{X_2}^2}{n_2}}$$

The $t.test$ function in R performs the Welch t-test by default.


## 2.2 Randomization Test

Fisher suggested using _permutations_ of data to generate a numeric equivalent to the parametric t-test. Data is randomly sampled into the two groups under the Null hypothesis that they have the same mean (therefore it is valid to randomly sample from the two groups to calculate an overall mean since we assume both samples are generated from a distribution with the same mean). This is done some large number $B$ times, yielding permutation t-values $t_1^*, t_2^*, ..., t_B^*$, generating a distribution of t-values under the Null Hypothesis. The two-sided permutation significance level for the original value $t$ is then the proportion of the $t_b^*$ values exceeding $t$ in absolute value:

$$p-value = \frac{|t_b^*| \geq |t|}{B}$$

The p-value returned gets smaller as the absolute value of the test statistic $t$ increases relative to the permutation test statistics, $t_b^*$, suggested the observed test statistic is unlikely to come from the distribution of $t_b^*$ under the Null hypothesis.

__Randomization Test Algorithm__

1) Define B as the number of permutations
2) for b = 1, ..., B
  2.1) Sample a permutation of the data
  2.2) Calculate the test statistic $T_b^{(R)}$ for this permutation
3) Count the number of permutations, $m$, for which $T_b^{(R)} \geq T^{(Obs)}$
4) p-value = $\frac{m}{B}$

Randomization tests may be particularly useful when the distribution of the data is strongly different to that of a normal distribution and the sample size is small (such that the results of the Central Limit Theorem have a limited impact on the distribution of the mean).

<div class="alert alert-info">
  <strong>The caveats of p-values</strong> 
  
  A _p-value_ represents the probability of seeing a test statistic at least as extreme as the one observed, under the Null hypothesis that the test statistic came from the null distribution. An experimenter who rejects a null hypothesis if the p-value is at most $\alpha_0$ is using a test with level of significance $\alpha_0$.
  
  The choice of significance threshold, $\alpha_0$, for rejection of the Null hypothesis is arbitrary. Typically we take $\alpha_0 = 0.05$ but by definition this yields a type-1 error (incorrectly reject the null hypothesis) with probability 0.05. That is, there is a probability of $0.05$ that we incorrectly reject the null hypothesis if it is actually true because whilst we might observe a test statistic at the extremes of the distribution of test statistics under the null, there is still non-zero probability the statistic was drawn from the null distribution. 
  
  Therefore one should be careful when using p-values to reject or accept hypotheses. Often it is prudent to also consider prior domain knowledge to guide our beliefs when assessing p-values.
  
</div>


## 2.3 Size and Power

__Definition- Size of a Test__

The __Size__ of a test is the probability of incorrectly rejecting the null $H_0$, also known as the “type-1" error. Usually the size and significance level $\alpha_0$ for a test are the same (by definition).

__Definition- Power of a Test__

The __Power__ of a test is the probability of rejecting $H_0$ given that the null is false (i.e. the alternative hypothesis is true). 

One test might be considered 'better' than another if, for a given significance level (size) $\alpha_0$, it has a greater power (lower probabilty of making "type-2" errors). Therefore, we would like tests that exhibit high power for a given significance level/test size. 


<div class="alert alert-info">
  <strong>Power Analysis</strong> 
  
Power analysis can be used to calculate the minimum sample size required so that one can be reasonably likely to detect an effect of a given size. This is used in the Design of Experiments, for example in Medical Statistics trials to assess the number of patients required to achieve a pre-defined test power. 

</div>

# 3 United States Murder Rates

```{r 2-prepare-data, results = FALSE}
data("murders")
dtMurders <- as.data.table(murders)[grepl("south|North", 
              region, ignore.case = TRUE), ]
dtMurders[grepl("North", region, ignore.case = TRUE), 
          region := "North"]
```

Below we see the murder rate per million for US States in 2010^[Murder data: https://rdrr.io/cran/dslabs/src/R/murders.R]:

```{r 3-murder-rate-table}
# Calculate murder rate per million to adjust for exposure
rmarkdown::paged_table(dtMurders[, Rate := 1000000 * total / population])
```


## 3.1 Exploratory Data Analysis

This brief exploratory analysis supports our initial hypothesis that Southern states have higher murder rates than Northern states. However, Southern states have a much greater variation in the murder rate, driven mainly by the outlying District of Colombia, lying more than 2 standard deviations away from the mean murder rate for Southern states. This high variance places some uncertainty around the conclusion of differing murder rates between Northern and Southern states, particularly given the low sample size.

```{r}
pDens <- ggplot(dtMurders[region %in% c("South", "North")]) + 
  geom_density(aes(x = Rate, col = region)) +
  labs(col = "Test")
pBox <- ggplot(dtMurders[region %in% c("South", "North")]) +
  geom_boxplot(aes(x = region, y = Rate))+
  labs(col = "Test")
ggpubr::ggarrange(pDens, pBox, nrow = 1, ncol = 2)

# Mean murder rates for each region
kable(dtMurders[, .(Obs = .N, 
                    MurderRate = mean(Rate), 
                    Variance = var(Rate)), 
                by = region], 
      format = "markdown")

kable(dtMurders[region == "South" & 
            Rate > mean(dtMurders[region == "South", ]$Rate) + 2 * 
            sqrt(var(dtMurders[region == "South", ]$Rate)), 
          .(state, region, Rate)], 
      format = "markdown")
```


## 3.2 Randomization vs Two-Sample t-test

Whilst the sample size is small, it appears that the variation in murder rates is much higher in Southern States than Northern states, directing us towards the use of Welch's t-test which does not assume the population variances are equal between the two groups. 

__T-test Results__

```{r murder-rates-t-test}
tTestMurders <- t.test(dtMurders[region == "South", ]$Rate, 
                       dtMurders[region == "North", ]$Rate)
kable(data.table("Test Statistic" = tTestMurders$statistic, 
                 "P-Value" = tTestMurders$p.value, 
                 "Difference in Means" = 
                   mean(dtMurders[region == "South"]$Rate) - 
                   mean(dtMurders[region == "North"]$Rate),
                 "Lower 95% CI" = tTestMurders$conf.int[1], 
                 "Upper 95% CI" = tTestMurders$conf.int[2]))
```

__Randomization Test Results__

```{r murder-rates-randomization-test}
cTests <- 1000
randomTestpValue <- 
  randomFun(data = dtMurders[, .(region, Rate)], K = cTests, 
            colTest = "region", colResponse = "Rate", 
            levels = c("South", "North"))
kable(setDT(randomTestpValue[names(randomTestpValue) != "TRand"]), 
      format = "markdown")
```

The t-test yields a small p-value, with the 95% Confidence Interval for the difference in mean murder rates between Southern and Northern states not containing zero.

Interestingly, the distribution of Randomization test statistics appears to be strongly non-Gaussian:

```{r Randomization-statistic-distribution}
testValues <- 
  c("Mean Randomization Test Statistic" = mean(randomTestpValue$TRand), 
    unlist(randomTestpValue[c("Test Statistic", "Lower 95% CI",
                              "Upper 95% CI")]))
vlines <- data.table(xint = testValues, Values = names(testValues))
ggplot(data.table(randomTestpValue$TRand), aes(x = V1)) +
  geom_density(fill = "red", alpha = 0.2) +
  labs(x = "Randomization Test Statistic", y = "Density") +
  ggtitle("Density Plot of Randomization Test Statistic") +
  geom_vline(data = vlines[1:2, ], aes(xintercept = xint, colour = Values), 
             linetype = "dashed", size = 1) +
  geom_vline(data = vlines[3:4, ], 
             aes(xintercept = xint, colour = "95% Confidence Interval"),
             size = 1)
  
```

Because we have a _two-sided_ test, we take the __absolute value__ of the test statistic, as opposed to the value. We also see that the observed test statistic lies within the 95% confidence bands of the distribution of the test statistic under the Null hypothesis, corresponding with a p-value greater than 0.05.

# 4 Simulation Study

Given that repeating the randomization function many times can be computationally time-consuming, we consider randomization tests of 200 samples and repeat the tests 1000 times.

## 4.1 Scenario 1 – Sample Size

Smaller samples may reduce the power of tests to reject the null. Such samples may contain values far in the tails of the respective distributions and thus affect the size and power of these tests. We therefore consider the size and power of the two tests for samples of increasing size.
Simply calculating the mean of . Naturally we could increase the sample size and hence the power fo the test by simply considering that the number of murders in each state is the sum of murders for the counties that constitute each state. 

The sample size determines the amount of sampling error inherent in a test result. Other things being equal, effects are harder to detect in smaller samples. Increasing sample size is often the easiest way to boost the statistical power of a test. 

```{r helper-function, echo = TRUE}
HelpFun(SimulationFun)
```

```{r}
#Use the sampSizeFun function to calculate power and size for samples of
#increasing size
# Sample sizes to simulate. Doubling saves computational time and
# allows us to log-transform the scale
cSampSize <- 2 ^ seq(1, 10)
# storage datatable of results
matResults1 <- matrix(NA, nrow = length(cSampSize), ncol = 5)
matResults1[, 1] <- cSampSize
colnames(matResults1) <- c("Var", "rSizePower", "rAvgPValue",
                           "tSizePower", "tAvgPValue")
# create identical matrices for different scenarios
for (i in 2:4) {
  eval(call("<-", paste0("matResults", i), matResults1))
}

j <- 0
for (i in cSampSize) {
  j <- j + 1
  matResults1[j, 2:5] <- sapply(SimulationFun(N = i, K = 10, R = 10, 
                                              diff.means = 0.1), 
                            "[[", 1)[2:5]
}
#Plot of test power against sample size
# Could turn these plot calls into a function
ggplot(as.data.frame(matResults1)) + 
  geom_point(aes(x = Var, y = rAvgPValue, col = 'Randomization Test'),
             size = 3) + 
  geom_point(aes(x = Var, y = tAvgPValue, col = 't-test'), size = 3) + 
  labs(title = 'Test Power by Sample Size', x = 'Sample Size', 
  y = 'Power') + geom_line(aes(x = Var, y = rAvgPValue, 
  col = 'Randomization Test'), size = 1.2) + geom_line(aes(x = Var, 
  y = tAvgPValue, col = 't-test'), size = 1.2) + 
  scale_x_continuous(trans = 'log2')
#Plot of test size against sample size
ggplot(as.data.frame(matResults1)) + 
  geom_point(aes(x = Var, y = rSizePower, col = 'Randomization Test'), size = 2) + 
  geom_point(aes(x = Var, y = tSizePower, col = 'T-test'), size = 2) + 
  labs(title = 'Test Size for Increasing Sample Size', x = 'Log Sample Size', 
       y = 'Test Size') + 
  geom_line(aes(x = Var, y = rSizePower, col = 'Randomization Test'), size = 1) + 
  geom_line(aes(x = Var, y = tSizePower, col = 't-test'), size = 1)
```

Table 1- Size and Power for Increasing Sample Size
Sample Size	Randomization Size	Randomization Power	t-test Size	t-test Power

```{r}
kable(matResults1, format = "markdown")
```

We see that the power of the randomization sample increases as the number of randomized sample we calculate increases. Here we only simulate for randomized samples of size 500 given the computational time required for this process.

## 4.2 Scenario 2 - Difference in Means

```{r}
#2) Scenario 2

#Use the diffMeansFun function to calculate power and size for samples 
#with increasing differences in means
cDiffMeans <- seq(0, 0.9, 0.1)
j <- 0
for (i in cDiffMeans) {
  j <- j + 1
  matResults2[j, 2:5] <- sapply(SimulationFun(N = 20, K = 10, R = 10, 
                                              diff.means = i), 
                            "[[", 1)[2:5]
}

# Plot results
ggplot(as.data.frame(matResults2)) + 
  geom_point(aes(x = Var, y = rAvgPValue, col = 'Randomization Test'),
             size = 3) + 
  geom_point(aes(x = Var, y = tAvgPValue, col = 't-test'), size = 3) + 
  labs(title = 'Test Power by Sample Size', x = 'Sample Size', 
  y = 'Power', col = "Test") + geom_line(aes(x = Var, y = rAvgPValue, 
  col = 'Randomization Test'), size = 1.2) + geom_line(aes(x = Var, 
  y = tAvgPValue, col = 't-test'), size = 1.2) + 
  scale_x_continuous(trans = 'log2')

```


In this case, we consider differing scenarios in which the 
When considering the test size and power, we should consider that repetitions of 1000 are relatively low for testing the true power and size.


## 4.3 Scenario 3 - Variance

When we increase the variance of each distribution, we a similar result as when we reduce the difference in means between the two distributions

```{r variance}
# Scenario 3
cVar <- 2 ^ seq(-4, 5)
j <- 0
for (i in cVar) {
  j <- j + 1
  matResults3[j, 2:5] <- sapply(SimulationFun(N = 20, K = 10, R = 10, sd = i), 
                            "[[", 1)[2:5]
}

```

```{r}
kable(matResults3, format = "markdown")
```

Question- how close are the results of our randomization test relative to those of the t-test (i.e. is Normality a reasonable assumption?)


## 4.4 Scenario 4 - Deviation from Normality

For this question, it could be that there is a strong re-distribution of the murder rates between years and that 2010 is not representative of the long-run distributions in murder rates for each region. For example, it could be that states in the North East regions had a particularly low murder rate in 2010 compared to the long-run distribution of murder rates for each region. In this case, we may have a sample for 2010 that is at the tails of the long-run distribution for murder rates. The change in power as the difference in means increases is essentially what we would see if the variance of each sample was decreasing. In this case we get a test size of 0.057 for both the randomization test and two-sample t-test.

Fisherian methodology has faced criticism for its over-reliance on normal sampling assumptions. p-values are calculated based on theoretical t-distributions, which depend on Gaussian, or Normal, assumptions. 

<div class="alert alert-info">
  <strong>Is Normality a Reasonable Assumption?</strong> 
  
  In many cases it may not intuitively feel as though our data is normally distributed for this assumption in the Two-Sample T-Test to seem feasible. However, the _Central Limit Theorem_ ( __CLT__ ) tells us that the sample mean $\bar{X}_n$ of a large sample of random variables with mean $\mu$ and finite variance $\sigma^2$ has approximately a normal distribution with mean $\mu$ and variance $\frac{\sigma^2}{n}$.
  
  This result helps to justify the use of the normal distribution as a model for many variables that can be thought of as being made up of many independent parts. The CLT is therefore a formal statement of how normal distributions can approximate distributions of general sums or averages of i.i.d. random variables. For example, a person's height is influenced by many random factors. If the height of each person is determined by adding the values of these individual factors, then the distribution of the heights of a large number of persons will be approximately normally distributed. In general, the CLT indicates that the distribution of the sum of many random variables can be approximately normal, even though the distribution of each random variable in the sum differs from normality.
  
  A Normal distribution actually seems a reasonable assumption. The number of murders for each state is the addition of the number of murders at much more local levels, such as by county. Many factors will also impact on the number of murders. Therefore the total number of murders across states can be seen as the sum of many individual factors, therefore it is reasonable to assume an approximately normal distribution Of course, one caveat of this is that we can't have negative murders and by the continuous nature of the normal distribution, this will always be theoretically possible, even for a large mean estimate and small variance. 

</div>

So far, we have simulated murder rates for both regions using normal distributions. However, given the nature and distribution of murder rates (figure ?), it is clear that a normal distribution is not appropriate 

because murder rates are always positive and tend to have a more right-skewed distribution. We therefore simulate murder rates from a gamma distribution to understand how the size and power of the two tests are affected when the data is no longer normal.
The gamma distribution is defined as:

$$f(x) = \frac{\beta ^ {\alpha}}{\Gamma(\alpha)} x^{\alpha - 1} e^{-\beta x}$$

where $x > 0$ and $\alpha >0, \beta > 0$.

In this case “alpha” represents the shape of the distribution and “beta” represents the rate of the distribution. Importantly, the mean and variance of a gamma distribution is given by:

$$\mathbb{E}[x] = \frac{\alpha}{\beta}, ~ ~ Var[x] = \frac{\alpha}{\beta^2}$$

In particular, for given gamma parameters, we assess how the sample size affects the power and size of each test. However, if the sample size is sufficiently large, it will not matter if the data violates normality because, by the central limit theorem, the means will be normally distributed. In this case the sampling distribution for the t-statistic will be standard normally distributed and p-values will be valid. We find that this is generally the case for samples of size as low as 10. The more unusual the distribution of the data is and the less it resembles a normal distribution, the larger the sample size needs to be to ensure a stable test size and high power.

Do a 2 x 2 design where we vary both the gamma parameters and the sample size

```{r}
#3) Scenario 4
# Random gamma parameters
matGamma <- data.frame(rate1 = runif(10, 0, 10), rate2 = runif(10, 0, 10), 
                   shape1 = runif(10, 0, 10), shape2 = runif(10, 0, 10))

j <- 0
for (i in 1:nrow(matGamma)) {
  j <- j + 1
  matResults4[j, 2:5] <- 
    sapply(SimulationFun(N = 20, K = 10, R = 10,
      shape = unlist(matGamma[i, 1:2]), rate = unlist(matGamma[i, 3:4]), 
      distribution = "gamma"), "[[", 1)[2:5]
}

# Consider 2-dimensional plots for alpha and beta
```

<div class="alert alert-info">
  <strong>Central Limit Theorem when the Support is not the Whole Real Line</strong> 
  
  Naturally the murder rate cannot be negative. Therefore, the mean of the murder rate cannot be negative and must have the same support as the murder rate itself. This implies the assumption of a Normal distribution for $\bar{X}_n$ is invalid since the Normal distribution can have negative support. 
  
  However, the Central Limit Theorem is only exactly true asymptotically, that is, as $n \rightarrow \infty$. For any finite $n$, a normal approximation to the distribution of the sample mean will give positive probability to subsets of values that are outside the bounds of the true support. 
 
</div>


Problem with T-tests is they are _Parametric_ and therefore require assumptions about the distribution of the data (e.g. Normality) and assumptions about the distribution of the test statistic under the Null hypothesis (derived from assumptions about the distribution of the data).

Randomization tests are similar to _Permutation tests_. Under a permutation test, we permute the values across the 2 groups, since under our null hypothesis there is no difference in the value of interest. We then calculate the test statistic for each permutation, giving us a distribution of the test statistic under the Null hypothesis. Randomization tests are like permutation tests, except that only a random subset of all the possible permutations are generated.
We get an approximate distribution of the test statistic that is non-parametric hence requires no assumptions about the data.

In particular, given the shape of the histogram when plotting murder rates, we use variants of the gamma distribution, including the chi-squared distribution to assess how the power and size of these tests alter when the data have different distributions.
Whilst the t-test may not be valid for non-normal data, if the sample size is large enough then the t-test will be robust due to the central limit theorem. If the data is non-normal, then 
Generally, we see that the two-sided t-test tends to outperform the randomization test, except when the data is gamma distributed and no longer normal. Other methods could also have been used to assess the small sample properties of the two tests when the variance of each sample is different, when the variance increases so that there is greater overlap in the distributions of each region, or if other non-normal distributions were used to simulate the data.

In large enough samples, the t-test asymptotically approximates the Z-test. However, when there are strong deviations from normality, particularly for small sample sizes, a non-parametric alternative, such as the Randomization test, may have higher statistical power. 

Mention bootstrapping as something similar


There are 2 clear arguments about why we should believe the permutation significance level generated by randomization tests:


Randomization greatly strengthens the conclusions of a permutation test. In particular, _Experimental Randomization_ almost guarantees that confounding factors (age, weight, etc.) will be well-balanced between the treatment groups. Fisher's RCT (Randomized Control Trial) is still the gold standard for statistical inference in Medical trials. Randomization randomly assigns the experimental units to the possible treatment groups. 


<div class="alert alert-info">
  <strong>Confounding</strong> 
  
  Typically when testing a hypothesis we might consider __Confounding features__; variables correlated both with the target and explanatory features. Their ommitance can result in invalid conclusions of causation between the dependent and independent feature.
  
  For example, if we wanted to instead answer the question "does the area in which a person resides determine their chance of committing a murder". In order to answer this question fairly, we would need to control for other features that explain differences in the murder rate between Norther and Southern states, such as average income, employment rates and measures of deprivation. Once we control for these features in an appropriate model, it might be the case that the state a person is located in is no longer statistically significant in explaining murder rates. Theses alternative __Causal__ factors would be of particular importance in taking decisions to reduce murder rates in Southern states
 
</div>



Randomization tests can be extended to a plethora of scenarios. 

Link to the GitHub repository to see the code: https://github.com/Domscruton/statistical-power-analysis


# 4 Conclusion

This report has illustrated how test power and size change for the two tests as the samples upon which they act alter.


# 5 Code

__Randomization Function__

```{r randomization-function, echo = TRUE}
print("Hello World!")
```

__Simulation Function__

```{r}

```

__References__

Statistics How To. (2019). Parametric and Non -Parametric Data. Retrieved from https://www.statisticshowto.datasciencecentral.com/parametric-and-non-parametric-data/.

Death Penalty Information Centre. (2019). State-by-State. Retrieved from https://deathpenaltyinfo.org/state-and-federal-info/state-by-state.

RStudio Team (2016). RStudio: Integrated Development for R. RStudio, Inc., Boston, MA URL http://www.rstudio.com/.

Kutner, M., Li, W., Nachtsheim, C., Neter, J. (2013). Applied Linear Statistical Models. McGraw Hill Education.

Glennie, R. (2019). MT4113- Computing in Statistics. [Lecture Notes] University of St Andrews.

Bartlett, J. (September 28, 2013). The t-test and Robustness to Non-Normality. Retrieved from: https://thestatsgeek.com/2013/09/28/the-t-test-and-robustness-to-non-normality/
Lehman, E. (1999). Elements of Large Sample Theory. Springer-Verlag, New York.

DeGroot, M., Schervish, M. (2012). Probability and Statistics (4th Ed.). Pearson Education.